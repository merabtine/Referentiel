# -*- coding: utf-8 -*-
"""Gpairo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/122dEfq8Jn7rov8ZDIQEjz1xEPG5g67Tf
"""


import pandas as pd
import re

def nettoyer_desi_arti(valeur):
    if pd.isna(valeur):
        return valeur
    texte = str(valeur)
    texte = texte.lstrip()  # Supprimer les espaces au début
    texte = re.sub(r'^[^a-zA-Z0-9]+', '', texte)  # Supprimer les caractères spéciaux en début de chaîne
    return texte

def nettoyer_csv(input_file, output_file):
    # Charger le CSV
    df = pd.read_csv(input_file)

    # Nettoyer uniquement la colonne DESI_ARTI
    if 'DESI_ARTI' in df.columns:
        df['DESI_ARTI'] = df['DESI_ARTI'].apply(nettoyer_desi_arti)
    else:
        print("Erreur : colonne 'DESI_ARTI' introuvable.")

    # Sauvegarder le CSV nettoyé
    df.to_csv(output_file, index=False)
    print(f"Fichier nettoyé sauvegardé sous : {output_file}")



# Exemple d'utilisation
input_file = 'dataset_gpairo (1).csv'  # Remplacez par le chemin réel
output_file = 'dataset_gpairo_nettoye.csv'

nettoyer_excel(input_file, output_file)

import pandas as pd

def fusionner_csv(fichier1, fichier2, fichier_sortie):
    # Charger les deux fichiers CSV
    df1 = pd.read_csv(fichier1)
    df2 = pd.read_csv(fichier2)

    # Fusionner verticalement (concaténation des lignes)
    df_fusionne = pd.concat([df1, df2], ignore_index=True)

    # Sauvegarder dans un nouveau fichier CSV
    df_fusionne.to_csv(fichier_sortie, index=False)
    print(f"Fichiers fusionnés et sauvegardés sous : {fichier_sortie}")

# Exemple d'utilisation
fichier1 = 'dataset_gpairo.csv'
fichier2 = 'dataset_webpdrmif.csv'
fichier_sortie = 'dataset_gpairo_webpdrmif.csv'

fusionner_csv(fichier1, fichier2, fichier_sortie)

import pandas as pd

df = pd.read_csv("dataset_gpairo_webpdrmif.csv", encoding="utf-8-sig")

df.columns = [c.strip().upper() for c in df.columns]

df["DESI_ARTI"] = df["DESI_ARTI"].astype(str).str.strip().str.lower()

df_grouped = df.groupby("DESI_ARTI").apply(
    lambda group: list(zip(group["ID"], group["BASE"]))
).reset_index(name="PAIRES_ID_BASE")

df_grouped.to_csv("groupement_resultat.csv", index=False, encoding="utf-8-sig")

print("Fichier créé : groupement_resultat.csv")
print(f"Nombre total de lignes après regroupement : {len(df_grouped)}")

import pandas as pd
import csv
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from together import Together
from threading import Lock

client = Together(api_key="")

input_file = "groupement_resultat.csv"
output_file = "classification.csv"
inconnus_file = "inconnus.csv"

print("Lecture et nettoyage...")
df = pd.read_csv(input_file)
#df = df[df["ID"].notna()].drop_duplicates(subset="ID")  # ici y a pas de doublons c'est juste par sécurité
print(len(df))
df = df.head(500).copy()
#echantillon_x = df[df["BASE"] == "gpairo"].head(500)
#echantillon_y = df[df["BASE"] == "webpdrmif"].head(500)
#df = pd.concat([echantillon_x, echantillon_y]).copy()
print(len(df))

# Créer les fichiers de sortie avec les en-têtes
with open(output_file, "w", newline="", encoding="utf-8-sig") as f:
    csv.writer(f).writerow(["DESI_ARTI", "PAIRES_ID_BASE", "famille", "sous famille", "agregat", "nom produit"])

with open(inconnus_file, "w", newline="", encoding="utf-8-sig") as f:
    csv.writer(f).writerow(["DESI_ARTI", "PAIRES_ID_BASE", "designation_nettoyee"])

# Verrous pour éviter les conflits d'écriture
print_lock = Lock()
output_lock = Lock()
inconnus_lock = Lock()
log_file_path = "log.txt"

# Set pour tracker les IDs déjà traités et éviter les doublons
ids_traites = set()
traites_lock = Lock()

def nettoyer_et_classer_batch(designations, batch_id=0, exemples_precedents=None):
    prompt_intro = """
 Tu travailles sur une base de données industrielle de pièces de rechange pour des installations fixes et du matériel roulant.
Ta tâche pour chaque désignation brute fournie est de:
1. Nettoyer la désignation pour obtenir une version plus claire et normalisée.
2. Classer le produit en identifiant : la famille, la sous-famille, l'agrégat et le nom.

IMPORTANT : Chaque produit possède un champ PAIRES_ID_BASE. Ne le modifie jamais. Tu dois le renvoyer strictement identique dans ta réponse.

Tu dois traiter plusieurs désignations à la suite (batch). Assure-toi d'être cohérent : deux désignations similaires doivent donner les mêmes catégories, même si elles apparaissent dans des batchs séparés.
IMPORTANT : Tu dois OBLIGATOIREMENT remplir les 4 champs pour chaque désignation :

 Nettoyage :
- Supprime tous les éléments techniques inutiles, y compris :
  - Dimensions et mesures : chiffres (10, 160, 4P, 12 pouces, 40A, etc), diamètres (Ø), références (REF, reference, RF), longueurs (mm, pouces), tensions (V, W), pressions (bar).
  - Unités, symboles, positions : (A, V, W, mm, ", ', Q32, 4P, 2 positions, etc).
  - Codes techniques ou commerciaux et marques (atlas, parker, hyundai ...).
  - Couleurs, tailles (petit, grand), formes (rond, carré...).
  - Expressions commerciales comme "jeu de", "lot de", "assortiment de".

- Corrige les fautes d'orthographe fréquentes sans changer la nature du produit.
- Ajoute des espaces aux mots collés (ex : dejoint → de joint, interrupteuretanche → interrupteur étanche).
- Harmonise systématiquement les abréviations, variantes linguistiques et termes équivalents pour éviter les doublons (ex: synchro = synchronisation, ext = extérieur, int = intérieur, ar = arrière, av = avant ...)
- Ne jamais rajouter de commentaires.

 Classification (basée sur la désignation nettoyée uniquement) :
- Les catégories (famille, sous-famille, agrégat) doivent strictement rester dans le domaine des pièces de rechange pour installations fixes et matériel roulant, sans jamais sortir de ce périmètre.
- Ne crée pas de catégories trop spécifiques : préfère les formes simples, normalisées.
- La hiérarchie des catégories est la suivante (du plus général au plus spécifique) : FAMILLE → SOUS-FAMILLE → AGREGAT → NOM
- La famille regroupe plusieurs sous-familles, c'est une catégorie très large, unique et ne doit pas changer selon la formulation. (ex : mécanique, électrique).Elle doit être au singulier.
- La sous-famille est un regroupement large, jamais construit autour de la variante ou l'usage d'un produit spécifique. Elle est moins large que la famille mais plus large que l'agregat, elle regroupe plusieurs agregats.Elle doit être au pluriel.
- Un terme utilisé comme sous-famille dans une famille ne doit jamais devenir une famille à part entière par la suite(ex: si "signalisation" ou "outils" sont des sous-familles dans "mécanique", il ne faut jamais créer une famille "signalisation" ni "outils").
- Si un terme existe comme famille autonome (ex : "signalisation"), il est interdit de le recréer ensuite comme sous-famille dans une autre famille (comme "mécanique"). Ce produit doit être classé directement dans la famille existante ("signalisation").
- Le nom correspond généralement au produit individuel (il doit être au singulier) ou à sa désignation nettoyée.
- L'agregat doit être dérivé à partir du nom du produit (désignation nettoyée), en retirant les adjectifs (complet, rond, carré ...), matières (cuivre, huile, eau ...), compléments ou formes spécifiques pour ne garder que le mot principal (généralement le premier nom).
- L'agregat ne doit jamais être identique à la sous-famille sauf s'il n'existe vraiment aucun regroupement possible (cas des vis, boulons, etc.).
- L'agregat regroupe plusieurs noms de produits très proches (ex:anneau torique, anneau cuivre , anneau m2x5 -> anneaux; filtre à air, filtre huile -> filtres; arbre complet, arbre primaire -> arbre ) — il doit être au pluriel.
- Une même sous-famille ou agrégat peut exister dans plusieurs familles distinctes (ex: "famille: mécanique et sous_famille: outils", "famille: elecricité et sous_famille: outils")
- Lorsqu'un terme générique comme "composants" est utilisé en sous-famille, il doit être précisé selon la famille à laquelle il appartient(ex : "composants mécaniques" pour la famille "mécanique", "composants électriques" pour "électricité").


 Éviter :
- Les sous-familles comme "kit de joints", "jeu de...", "à tête..." → préférer des formes simples : joints, vis...
- Les réponses floues comme "embrayage et sélecteur" ou toute catégorie avec "et" ou combinaison hasardeuse.
- De creer des sous_familles ou des agregats à partir de mots comme "à tête", "à bout", "à embout", "avec", etc.
- De creer plusieurs catégories (famille " ex: elecrique = elecricité  → elecricité, outils = outillage  → outillage, chimie = chimique  → chimie, sécurité = protection  → sécurité " ou agregat "ex: vis, vis parker, vis à bois, vis abois  → vis" , faut prendre la catégorie la plus générale.
- La multiplication excessive des sous-familles : regroupe les agrégats proches dans une même sous-famille plutôt que créer des sous-familles spécifiques pour chaque variante. Exemple : préfère une seule sous-famille "barres" plutôt que "barres de connexion", "barres de stabilisation", etc.
- De creer les familles ou sous familles comme "produits chimiques", "produits de peinture", "produits électriques", etc. Préférer des catégories génériques et universelles (chimie, peinture, electricité).
- De créer deux catégories distinctes à cause d'un accent manquant ou incorrect, utilise la forme orthographiquement correcte en français (avec accents) pour la catégorie finale (ex: boites = boîtes → boîtes)
- De créer une famille à partir d'un nom qui a déjà été utilisé comme sous-famille dans une autre famille(ex: si la sous-famille "outils" existe dans la famille "mécanique", il est interdit de créer par la suite une famille "outils"). Ces termes doivent rester des sous-familles, pas devenir des familles.

 Format de réponse strict pour chaque désignation :

DESIGNATION: [désignation brute]
PAIRES_ID_BASE: [ID_BASE fourni]
FAMILLE: ...
SOUS_FAMILLE: ...
AGREGAT: ...
NOM: [désignation nettoyée]

 Exemple :

DESIGNATION : anneau cuivre
PAIRES_ID_BASE: [(43,gpairo),(5678,webpdrmif)]
FAMILLE: mécanique
SOUS_FAMILLE: bagues
AGREGAT: anneaux
NOM: anneau cuivre

Maintenant, traite les désignations suivantes :
"""


    for designation, liste_paires in designations:
        prompt_intro += f"\nPAIRES_ID_BASE : {liste_paires}\nDESIGNATION : {designation.strip().lower()}\n"

    try:
        completion = client.chat.completions.create(
            model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
            messages=[{"role": "user", "content": prompt_intro}],
            temperature=0.3,
            max_tokens=1000
        )

        response = completion.choices[0].message.content.strip()
        blocs = response.split("\n\n")  # chaque bloc = une désignation traitée

        results = []
        found_designations = set()

        for bloc in blocs:
            lines = bloc.strip().splitlines()
            result = {
                "designation": "",
                "paires_id_base": [],
                "famille": "inconnue",
                "sous_famille": "inconnue",
                "agregat": "inconnu",
                "nom": ""
            }

            for line in lines:
                if ":" not in line:
                    continue
                cle, valeur = line.split(":", 1)
                cle = cle.strip().lower()
                valeur = valeur.strip().lower()

                if "designation" in cle:
                    result["designation"] = valeur
                    found_designations.add(valeur)
                elif cle in result:
                    result[cle] = valeur


            if not result["sous_famille"] or result["sous_famille"] in ["inconnu", "inconnue"]:
                result["sous_famille"] = result["agregat"]
            if not result["agregat"] or result["agregat"] in ["inconnu", "inconnue"]:
                result["agregat"] = result["sous_famille"]

            if result["paires_id_base"]:
                results.append(result)

        results_dict = {str(r["paires_id_base"]).strip(): r for r in results}

        # Construire les résultats finaux dans l'ordre d'entrée
        final_results = []
        for designation, paires_id_base in designations:
         paires_str = str(paires_id_base).strip()  # Utilisation de la paire comme clé texte

         if paires_str in results_dict:
           final_results.append(results_dict[paires_str])
         else:
          final_results.append({
            "designation": designation.strip().lower(),
            "paires_id_base": paires_id_base,
            "famille": "inconnue",
            "sous_famille": "inconnue",
            "agregat": "inconnu",
            "nom": ""
        })


        taux = round(100 * len([r for r in final_results if r["famille"] != "inconnue"]) / len(designations)) if designations else 0
        print(f"[Batch {batch_id}] : {len([r for r in final_results if r['famille'] != 'inconnue'])}/{len(designations)} traitées avec succès ({taux}%)")

        return final_results

    except Exception as e:
        print(f"[Erreur batch {batch_id}]:", e)

        return [{
            "designation": d.strip().lower(),
            "paires_id_base": paires_id_base,
            "famille": "inconnue",
            "sous_famille": "inconnue",
            "agregat": "inconnu",
            "nom": ""
        } for d, paires_id_base in designations]

def charger_exemples_depuis_output(fichier, max_exemples=10):
    exemples = []
    try:
        with open(fichier, mode="r", encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            for row in reader:
                exemples.append({
                    "pires_id_base": row["PAIRES_ID_BASE"].strip(),
                    "designation": row["DESI_ARTI"].strip(),
                    "famille": row["famille"].strip(),
                    "sous_famille": row["sous famille"].strip(),
                    "agregat": row["agregat"].strip(),
                    "nom": row["nom produit"].strip(),
                })
    except Exception as e:
        print(f"Erreur lecture output_file pour les exemples : {e}")

    return exemples[:max_exemples]

import ast
historique = []

def traiter_batch(batch_id, batch):
    global ids_traites

    # batch : liste de (index, row), on extrait DESIGNATION + PAIRES_ID_BASE (liste de tuples)
    id_designations = [(row[1]["DESI_ARTI"], row[1]["PAIRES_ID_BASE"]) for row in batch]

    with traites_lock:
        ids_a_traiter = []
        for designation, liste_paires_str in id_designations:
            # Transformer la chaîne en liste Python
            liste_paires = ast.literal_eval(liste_paires_str) if isinstance(liste_paires_str, str) else liste_paires_str

            # Filtrer toutes les paires non traitées, et ajouter la désignation avec toutes ses paires non traitées
            nouvelles_paires = []
            for id_val, base_val in liste_paires:
                identifiant_unique = (id_val, base_val)
                if identifiant_unique not in ids_traites:
                    ids_traites.add(identifiant_unique)
                    nouvelles_paires.append((id_val, base_val))

            if nouvelles_paires:
                # On ajoute une fois par désignation avec uniquement les paires non traitées
                ids_a_traiter.append((designation, nouvelles_paires))

        if not ids_a_traiter:
            print(f"[Batch {batch_id}] : Tous les IDs déjà traités, passage...")
            return

    exemples = None
    results = nettoyer_et_classer_batch(ids_a_traiter, batch_id=batch_id, exemples_precedents=exemples)

    # Ajustement des clés pour cohérence
    for res in results:
        res["DESI_ARTI_ORIG"] = res["designation"]
        res["PAIRES_ID_BASE"] = res["paires_id_base"]

    # Mise à jour historique
    for res in results:
        if res["famille"] != "inconnue":
            historique.append(res)

    with print_lock:
        with open(log_file_path, "a", encoding="utf-8") as logf:
            for res in results:
                log_line = f"{res.get('DESI_ARTI_ORIG')} ➜ [{res['famille']} / {res['sous_famille']} / {res['agregat']} / {res['nom']}]\n"
                logf.write(log_line)

    reussites = []
    echecs = []

    for res in results:
        if (res["famille"] != "inconnue" and
            all(res.get(k, "").strip().lower() not in ["", "inconnu", "inconnue"] for k in ["famille", "sous_famille", "agregat", "nom"])):
            reussites.append(res)
        else:
            echecs.append(res)

    if reussites:
        with output_lock:
            with open(output_file, "a", newline="", encoding="utf-8-sig") as f:
                writer = csv.writer(f)
                for res in reussites:
                    writer.writerow([
                        res.get("DESI_ARTI_ORIG", res["designation"]),
                        str(res["PAIRES_ID_BASE"]),
                        res["famille"],
                        res["sous_famille"],
                        res["agregat"],
                        res["nom"]
                    ])

    if echecs:
        with inconnus_lock:
            with open(inconnus_file, "a", newline="", encoding="utf-8-sig") as f:
                writer = csv.writer(f)
                for res in echecs:
                    writer.writerow([
                        res.get("DESI_ARTI_ORIG", res["designation"]),
                        str(res["PAIRES_ID_BASE"]),
                        ""
                    ])

    time.sleep(3.5)

def retraiter_inconnus(max_retentatives, batch_size):
    global ids_traites

    for tentative in range(1, max_retentatives + 1):
        with open(inconnus_file, "r", encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            inconnus = []
            for row in reader:
                desi = row["DESI_ARTI"].strip()
                paires_str = row["PAIRES_ID_BASE"].strip()
                if desi and paires_str:
                    inconnus.append((desi, paires_str))

        if not inconnus:
            print("Aucun inconnu à traiter.")
            break

        print(f"\nRetraitement tentative {tentative} ({len(inconnus)} inconnus)...")

        exemples = charger_exemples_depuis_output(output_file, max_exemples=10)

        batched_inconnus = [inconnus[i:i+batch_size] for i in range(0, len(inconnus), batch_size)]
        all_results = []

        def traiter_batch_inconnu(i_batch, batch):
            # batch est liste de (DESI_ARTI, PAIRES_ID_BASE_str)
            results = nettoyer_et_classer_batch(batch, batch_id=f"RETRY-{tentative}-{i_batch+1}", exemples_precedents=exemples)
            for res in results:
                res["DESI_ARTI_ORIG"] = res["designation"]
                res["PAIRES_ID_BASE"] = res["paires_id_base"]
            return results

        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {executor.submit(traiter_batch_inconnu, i, batch): i for i, batch in enumerate(batched_inconnus)}

            for future in tqdm(as_completed(futures), total=len(futures), desc=f"Retraitement {tentative}"):
                try:
                    results = future.result()
                    all_results.extend(results)
                except Exception as e:
                    print(f"[Erreur thread retraitement batch {futures[future]}] {e}")

        reussites = []
        echecs = []

        for res in all_results:
            if (res["famille"] != "inconnue" and
                all(res.get(k, "").strip().lower() not in ["", "inconnu", "inconnue"]
                    for k in ["famille", "sous_famille", "agregat", "nom"])):
                reussites.append(res)
            else:
                echecs.append(res)

        if reussites:
            with open(output_file, "a", newline="", encoding="utf-8-sig") as f:
                writer = csv.writer(f)
                for res in reussites:
                    writer.writerow([
                        res.get("DESI_ARTI_ORIG", res["designation"]),
                        str(res["PAIRES_ID_BASE"]),
                        res["famille"],
                        res["sous_famille"],
                        res["agregat"],
                        res["nom"]
                    ])

        with open(inconnus_file, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerow(["DESI_ARTI", "PAIRES_ID_BASE", "designation_nettoyee"])
            for res in echecs:
                writer.writerow([
                    res.get("DESI_ARTI_ORIG", res["designation"]),
                    str(res["PAIRES_ID_BASE"]),
                    ""
                ])

        print(f"[Retry {tentative}] : {len(reussites)}/{len(inconnus)} traités. Restants : {len(echecs)}")

batch_size = 50
max_retentatives = 3

# Préparation des données
rows = list(df.iterrows())
batch_list = [rows[i:i+batch_size] for i in range(0, len(rows), batch_size)]

print(f"\nDémarrage du traitement en parallèle ({len(rows)} lignes, {len(batch_list)} batches)...")
start = time.time()

# Traitement principal
with ThreadPoolExecutor(max_workers=4) as executor:
    list(tqdm(executor.map(lambda args: traiter_batch(*args), enumerate(batch_list, 1)), total=len(batch_list)))

# Retraitement des inconnus
batch_size_inconnus = 50
retraiter_inconnus(max_retentatives, batch_size_inconnus)

duration = time.time() - start
h = int(duration // 3600)
m = int((duration % 3600) // 60)
s = int(duration % 60)
print(f"\nTemps total d'exécution : {h}h {m}mn {s}s")

# Vérification finale
print(f"\nVérification finale:")
#print(f"Nombre d'IDs traités : {len(ids_traites)}")
with open(output_file, "r", encoding="utf-8-sig") as f:
    reader = csv.DictReader(f)
    output_count = sum(1 for _ in reader)
    print(f"Nombre de lignes dans output_file : {output_count}")
    Nb_inconnus = len(df) - output_count
    print(f"Nombre d'inconnus : {Nb_inconnus}")

max_retentatives = 3
batch_size_inconnus = 30
retraiter_inconnus(max_retentatives, batch_size_inconnus)

duration = time.time() - start
h = int(duration // 3600)
m = int((duration % 3600) // 60)
s = int(duration % 60)
print(f"\nTemps total d'exécution : {h}h {m}mn {s}s")

# Vérification finale
print(f"\nVérification finale:")
#print(f"Nombre d'IDs traités : {len(ids_traites)}")
with open(output_file, "r", encoding="utf-8-sig") as f:
    reader = csv.DictReader(f)
    output_count = sum(1 for _ in reader)
    print(f"Nombre de lignes dans output_file : {output_count}")
    Nb_inconnus = len(df) - output_count
    print(f"Nombre d'inconnus : {Nb_inconnus}")

df = pd.read_csv("classification.csv")
df = df[df["DESI_ARTI"].notna()].drop_duplicates(subset="DESI_ARTI")  # ici y a pas de doublons c'est juste par sécurité
print(len(df))

import csv
import ast

def degrouper_fichier(input_file_grouped, output_file_degrouped):
    with open(input_file_grouped, "r", encoding="utf-8-sig") as f_in, \
         open(output_file_degrouped, "w", newline="", encoding="utf-8-sig") as f_out:

        reader = csv.DictReader(f_in)
        fieldnames = ["ID", "BASE", "DESI_ARTI", "FAMILLE", "SOUS_FAMILLE", "AGREGAT", "NOM PRODUIT"]
        writer = csv.DictWriter(f_out, fieldnames=fieldnames)
        writer.writeheader()

        for row in reader:
            paires_str = row.get("PAIRES_ID_BASE", "[]")
            try:
                paires = ast.literal_eval(paires_str)
            except Exception as e:
                print(f"Erreur de conversion PAIRES_ID_BASE: {e}, ligne ignorée")
                continue

            for id_val, base_val in paires:
                writer.writerow({
                    "ID": id_val,
                    "BASE": base_val,
                    "DESI_ARTI": row.get("DESI_ARTI", ""),
                    "FAMILLE": row.get("famille", ""),
                    "SOUS_FAMILLE": row.get("sous famille", ""),
                    "AGREGAT": row.get("agregat", ""),
                    "NOM PRODUIT": row.get("nom produit", "")
                })

    print(f"Fichier dégroupé écrit dans {output_file_degrouped}")
degrouper_fichier("produits_groupes_corriges.csv", "resultat_dégroupé.csv")

import pandas as pd

# Charger le fichier CSV
df = pd.read_csv("classification (2).csv", encoding="utf-8-sig")

# Créer la colonne clé en utilisant un identifiant unique par combinaison sous_famille + agregat
df["clé"] = (df["sous famille"].fillna('') + "___" + df["agregat"].fillna('')).astype('category').cat.codes + 1

# Sauvegarder le fichier avec la nouvelle colonne
df.to_csv("produits_groupes.csv", index=False, encoding="utf-8-sig")

print(" Fichier exporté avec la clé de regroupement.")

import pandas as pd

# Charger le fichier
df = pd.read_csv("produits_groupes.csv", encoding="utf-8-sig")

# Ne garder que les colonnes souhaitées
df_grouped = df[["clé", "sous famille", "agregat"]].drop_duplicates()

# Trier par clé pour plus de lisibilité (optionnel)
df_grouped = df_grouped.sort_values("clé")

# Sauvegarder le fichier regroupé
df_grouped.to_csv("groupes_sous_famille_agregat.csv", index=False, encoding="utf-8-sig")

print("Fichier regroupé exporté.")

import pandas as pd

# Charger ton fichier regroupé
df = pd.read_csv("groupes_sous_famille_agregat.csv", encoding="utf-8-sig")

# Générer le bloc de tableau CSV en texte brut
bloc_tableau = df.to_csv(index=False, line_terminator="\n")

# Construire le prompt complet
prompt = f"""
Tu es un expert en classification produit dans le domaine des pièces de rechange pour installations fixes et matériel roulant.

Je te fournis un tableau : chaque ligne contient une clé, une sous famille actuelle et un agregat actuel.

---

Objectif :

Corrige la classification de la sous famille et de l’agregat si nécessaire, en respectant les règles suivantes :

1. La sous famille :
   - Doit être une catégorie large, englobant plusieurs agrégats.
   - Ne doit pas être spécifique ni construite autour d'un produit individuel.
   - Doit être au pluriel si possible.
   - Ne crée pas une sous famille plus précise que l’agregat.

2. L’agregat :
   - C’est un regroupement de produits très proches.
   - Doit être au pluriel si possible.

3. Relation hiérarchique :
   - La sous famille doit toujours être plus large que l’agregat.

4. Ne jamais sortir du domaine des pièces de rechange.

---

Format de réponse strict :

Pour chaque clé_groupe, retourne :

- clé : X
- sous famille corrigée : ...
- agregat corrigé : ...

---

Voici le tableau :

{bloc_tableau}

---

Instructions :

Corrige uniquement si nécessaire. Réponds uniquement avec le tableau final corrigé.
"""

# Lire la réponse brute générée par le modèle
with open("correction.txt", "r", encoding="utf-8-sig") as f:
    lignes = f.readlines()

# Extraire les données structurées (filtrage simple)
resultats = []
cle, sous_famille, agregat = None, None, None

for ligne in lignes:
    ligne = ligne.strip()
    if ligne.lower().startswith("clé") or ligne.lower().startswith("clé"):
        cle = ligne.split(":")[1].strip()
    elif ligne.lower().startswith("sous famille corrigée"):
        sous_famille = ligne.split(":")[1].strip()
    elif ligne.lower().startswith("agregat corrigé"):
        agregat = ligne.split(":")[1].strip()

    # Lorsque les 3 infos sont remplies, on ajoute la ligne au tableau final
    if cle and sous_famille and agregat:
        resultats.append({
            "clé": cle,
            "sous_famille_corrigée": sous_famille,
            "agregat_corrigé": agregat
        })
        cle, sous_famille, agregat = None, None, None  # Réinitialisation

# Convertir en DataFrame
df_final = pd.DataFrame(resultats)

# Sauvegarder en CSV
df_final.to_csv("correction.csv", index=False, encoding="utf-8-sig")

print(" Le fichier classification_corrigee.csv a été généré.")

from together import Together
import pandas as pd
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

client = Together(api_key="b1e91748251003b14286a7b425fedcd45cce16b718ccb91eae6a7a1695c895d8")

# Charger le fichier
df = pd.read_csv("groupes_sous_famille_agregat.csv", encoding="utf-8-sig")

# Préparer les données : liste (description, clé)
designations = []
for _, row in df.iterrows():
    key = str(row["clé"])
    sous_famille = str(row["sous famille"]).strip().lower()
    agregat = str(row["agregat"]).strip().lower()
    description = f"{sous_famille} {agregat}"
    designations.append((description, key))

batch_size = 100
batches = [designations[i:i+batch_size] for i in range(0, len(designations), batch_size)]

def traiter_batch(batch_index, batch):
    prompt_intro = """
Tu es un expert en classification produit dans le domaine des pièces de rechange pour installations fixes et matériel roulant.

Objectif :

Corrige la classification de la sous famille et de l’agregat si nécessaire, en respectant les règles suivantes :

1. La sous famille :
   - Doit être une catégorie large, englobant plusieurs agrégats.
   - Ne doit pas être spécifique ni construite autour d'un produit individuel.
   - Doit être au pluriel si possible.
   - Ne crée pas une sous famille plus précise que l’agregat.

2. L’agregat :
   - C’est un regroupement de produits très proches.
   - Doit être au pluriel si possible.

3. Relation hiérarchique :
   - La sous famille doit toujours être plus large que l’agregat.

4. Ne jamais sortir du domaine des pièces de rechange.

---

Pour chaque clé fournie, retourne uniquement :

- clé : X
- sous famille corrigée : ...
- agregat corrigé : ...

Exemple:
- clé : 1245
- sous famille : bobine de démarrage
- agregat : bobine

->
- clé : 1245
- sous famille corrigée : bobine
- agregat corrigé : bobine de démarrage
"""

    for description, key in batch:
        prompt_intro += f"\nclé : {key}\nsous famille actuelle : {description.strip()}\n"

    try:
        completion = client.chat.completions.create(
            model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
            messages=[{"role": "user", "content": prompt_intro}],
            temperature=0.3,
            max_tokens=5000
        )

        response = completion.choices[0].message.content.strip()

        # Parse réponse
        lignes = response.splitlines()
        cle, sous_famille, agregat = None, None, None
        batch_results = []

        for ligne in lignes:
            ligne = ligne.strip()
            if ligne.lower().startswith("clé"):
                cle = ligne.split(":", 1)[1].strip()
            elif "sous famille corrigée" in ligne.lower():
                sous_famille = ligne.split(":", 1)[1].strip()
            elif "agregat corrigé" in ligne.lower():
                agregat = ligne.split(":", 1)[1].strip()

            if cle and sous_famille and agregat:
                batch_results.append({
                    "clé": cle,
                    "sous_famille_corrigée": sous_famille,
                    "agregat_corrigé": agregat
                })
                cle, sous_famille, agregat = None, None, None

        print(f"\n[Batch {batch_index + 1}] Résultats :")
        for res in batch_results:
            print(res)

        # Petite pause pour éviter de trop saturer l'API
        pd.DataFrame(batch_results).to_csv(
            "correction.csv",
            mode='a',
            header=False,
            index=False,
            encoding="utf-8-sig"
        )

        time.sleep(1)
        return batch_results

    except Exception as e:
        print(f"[Batch {batch_index + 1}] Erreur :", e)
        # En cas d'erreur, retourne des résultats "inconnus" pour toutes les désignations du batch
        return [{
            "clé": key,
            "sous_famille_corrigée": "inconnue",
            "agregat_corrigé": "inconnu"
        } for _, key in batch]

# Exécution multithread avec 4 workers (ajuste selon ta machine/limites API)
final_results = []

for batch_index, batch in enumerate(batches):
    resultats_batch = traiter_batch(batch_index, batch)
    final_results.extend(resultats_batch)

print("\n Traitement terminé : correction.csv")

from together import Together
import pandas as pd
import time
from tqdm import tqdm

client = Together(api_key="b1e91748251003b14286a7b425fedcd45cce16b718ccb91eae6a7a1695c895d8")

# Charger le fichier
df = pd.read_csv("groupes_sous_famille_agregat.csv", encoding="utf-8-sig")

# Préparer les données
designations = []
for _, row in df.iterrows():
    key = str(row["clé"])
    sous_famille = str(row["sous famille"]).strip().lower()
    agregat = str(row["agregat"]).strip().lower()
    description = f"{sous_famille} {agregat}"
    designations.append((description, key))

batch_size = 100
batches = [designations[i:i+batch_size] for i in range(0, len(designations), batch_size)]

# Initialiser le fichier CSV
pd.DataFrame(columns=["clé", "sous_famille_corrigée", "agregat_corrigé"]).to_csv(
    "correction.csv", index=False, encoding="utf-8-sig"
)

# Mémoire cumulative des exemples
exemples_injectes = set()
resultats_cumules = []  # Historique complet pour construire les exemples

# Traitement batch par batch
for batch_index, batch in enumerate(tqdm(batches, desc="Traitement des batchs")):
    print(f"\n--- Batch {batch_index+1}/{len(batches)} ---")

    # Générer des exemples à partir de la mémoire cumulative
    exemples_textes_list = []
    for r in resultats_cumules:
        sous_famille = str(r["sous_famille_corrigée"]).strip().lower()
        agregat = str(r["agregat_corrigé"]).strip().lower()
        if sous_famille != "inconnue" and sous_famille not in exemples_injectes:
            exemples_textes_list.append(
                f"- clé : {r['clé']}\n- sous famille : {sous_famille}\n- agregat : {agregat}\n"
            )
            exemples_injectes.add(sous_famille)

    print(f"\n• {len(exemples_textes_list)} exemples injectés dans le prompt.\n")
    for exemple in exemples_textes_list:
        print(exemple)

    exemples_textes = "\n".join(exemples_textes_list)

    # Construire le prompt
    prompt_intro = """
Tu es un expert en classification produit dans le domaine des pièces de rechange pour installations fixes et matériel roulant.

Objectif :

Corrige la classification de la sous famille et de l’agregat si nécessaire, en respectant les règles suivantes :

1. La sous famille :
   - Doit être une catégorie large, englobant plusieurs agrégats.
   - Ne doit pas être spécifique ni construite autour d'un produit individuel.
   - Doit être au pluriel si possible.
   - Ne crée pas une sous famille plus précise que l’agregat.

2. L’agregat :
   - C’est un regroupement de produits très proches.
   - Doit être au pluriel si possible.

3. Relation hiérarchique :
   - La sous famille doit toujours être plus large que l’agregat.

4. Ne jamais sortir du domaine des pièces de rechange.

Exemple:
- clé : 1245
- sous famille : bobine de démarrage
- agregat : bobine

->
- clé : 1245
- sous famille corrigée : bobine
- agregat corrigé : bobine de démarrage

Voici des exemples de classification correcte :
""" + exemples_textes + """


Pour chaque clé fournie, retourne uniquement :

- clé : X
- sous famille corrigée : ...
- agregat corrigé : ...
"""

    for description, key in batch:
        prompt_intro += f"\nclé : {key}\nsous famille actuelle : {description.strip()}\n"

    try:
        completion = client.chat.completions.create(
            model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
            messages=[{"role": "user", "content": prompt_intro}],
            temperature=0.3,
            max_tokens=5000
        )

        response = completion.choices[0].message.content.strip()

        # Parsing
        lignes = response.splitlines()
        cle, sous_famille, agregat = None, None, None
        batch_results = []

        for ligne in lignes:
            ligne = ligne.strip()
            if ligne.lower().startswith("clé"):
                cle = ligne.split(":", 1)[1].strip()
            elif "sous famille corrigée" in ligne.lower():
                sous_famille = ligne.split(":", 1)[1].strip()
            elif "agregat corrigé" in ligne.lower():
                agregat = ligne.split(":", 1)[1].strip()

            if cle and sous_famille and agregat:
                batch_results.append({
                    "clé": cle,
                    "sous_famille_corrigée": sous_famille,
                    "agregat_corrigé": agregat
                })
                cle, sous_famille, agregat = None, None, None

        nb_valides = sum(1 for r in batch_results if r["sous_famille_corrigée"].lower() != "inconnue")
        print(f"[Batch {batch_index+1}] {nb_valides}/{len(batch_results)} traités correctement.")

        for res in batch_results:
            print(res)

        # Mise à jour du CSV et de la mémoire cumulative
        pd.DataFrame(batch_results).to_csv(
            "correction.csv",
            mode='a',
            header=False,
            index=False,
            encoding="utf-8-sig"
        )

        resultats_cumules.extend(batch_results)  # Mémorisation pour les prochains batches

        print(f"[Batch {batch_index+1}] Résultats ajoutés à correction.csv.\n")

        time.sleep(1)

    except Exception as e:
        print(f"[Batch {batch_index+1}] Erreur :", e)
        continue

print("\n Tous les batchs traités. Résultat final : correction.csv")

from together import Together
import pandas as pd
import time
from tqdm import tqdm

client = Together(api_key="b1e91748251003b14286a7b425fedcd45cce16b718ccb91eae6a7a1695c895d8")

# Charger le fichier
df = pd.read_csv("groupes_sous_famille_agregat.csv", encoding="utf-8-sig")

# Préparer les données
designations = []
for _, row in df.iterrows():
    key = str(row["clé"])
    sous_famille = str(row["sous famille"]).strip().lower()
    agregat = str(row["agregat"]).strip().lower()
    description = f"{sous_famille} {agregat}"
    designations.append((description, key))

# Fonction : générer des exemples (limité)
def generer_exemples(resultats_cumules, max_exemples=30):
    exemples_injectes = set()
    exemples_textes = []

    for r in resultats_cumules:
        sous_famille = str(r["sous_famille_corrigée"]).strip().lower()
        agregat = str(r["agregat_corrigé"]).strip().lower()

        if sous_famille != "inconnue" and sous_famille not in exemples_injectes:
            exemples_textes.append(
                f"- clé : {r['clé']}\n- sous famille : {sous_famille}\n- agregat : {agregat}"
            )
            exemples_injectes.add(sous_famille)

        if len(exemples_textes) >= max_exemples:
            break

    return exemples_textes


# Fonction : traiter un batch
def traiter_batch(batch_index, batch, resultats_cumules):
    exemples_textes_list = generer_exemples(resultats_cumules)

    print(f"\n• {len(exemples_textes_list)} exemples injectés comme guide pour le batch {batch_index+1}.\n")
    for exemple in exemples_textes_list:
        print(exemple)

    exemples_textes = "\n".join(exemples_textes_list)

    prompt_intro = f"""

Tu es un expert en classification produit dans le domaine des pièces de rechange pour installations fixes et matériel roulant.

Objectif :

Corrige la classification de la sous famille et de l’agregat si nécessaire sinon les laisser à l'origine, en respectant les règles suivantes :

1. La sous famille :
   - Doit être une catégorie large, englobant plusieurs agrégats.
   - Ne doit pas être spécifique ni construite autour d'un produit individuel.
   - Doit être au pluriel si possible.
   - Ne crée pas une sous famille plus précise que l’agregat.

2. L’agregat :
   - C’est un regroupement de produits très proches.
   - Doit être au pluriel si possible.

3. Relation hiérarchique :
   - La sous famille doit toujours être plus large que l’agregat.

4. Ne jamais sortir du domaine des pièces de rechange.

Exemple:
- clé : 1245
- sous famille : bobine de démarrage
- agregat : bobine

->
- clé : 1245
- sous famille corrigée : bobine
- agregat corrigé : bobine de démarrage

Voici des exemples de classification correcte :
 {exemples_textes }


Pour chaque clé fournie, retourne uniquement :

- clé : X
- sous famille corrigée : ...
- agregat corrigé : ...
"""
    for description, key in batch:
        prompt_intro += f"\nclé : {key}\nsous famille actuelle : {description.strip()}"

    try:
        completion = client.chat.completions.create(
            model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
            messages=[{"role": "user", "content": prompt_intro}],
            temperature=0.3,
            max_tokens=5000
        )

        response = completion.choices[0].message.content.strip()
        lignes = response.splitlines()
        cle, sous_famille, agregat = None, None, None
        batch_results = []

        for ligne in lignes:
            ligne = ligne.strip()
            if ligne.lower().startswith("clé"):
                cle = ligne.split(":", 1)[1].strip()
            elif "sous famille corrigee" in ligne.lower():
                sous_famille = ligne.split(":", 1)[1].strip()
            elif "agregat corrige" in ligne.lower():
                agregat = ligne.split(":", 1)[1].strip()

            if cle and sous_famille and agregat:
                batch_results.append({
                    "clé": cle,
                    "sous_famille_corrigee": sous_famille,
                    "agregat_corrige": agregat
                })
                cle, sous_famille, agregat = None, None, None

        nb_valides = sum(1 for r in batch_results if r["sous_famille_corrigee"].lower() != "inconnue")
        print(f"[Batch {batch_index+1}] {nb_valides}/{len(batch_results)} cas traités.\n")

        for res in batch_results:
            print(res)

        pd.DataFrame(batch_results).to_csv(
            "correction.csv",
            mode='a',
            header=False,
            index=False,
            encoding="utf-8-sig"
        )

        print(f"[Batch {batch_index+1}] Résultats ajoutés au CSV.\n")
        return batch_results

    except Exception as e:
        print(f"[Batch {batch_index+1}] Erreur :", e)
        return []


# Initialisation CSV
pd.DataFrame(columns=["clé", "sous_famille_corrigee", "agregat_corrige"]).to_csv(
    "correction.csv", index=False, encoding="utf-8-sig"
)


# Traitement global
resultats_cumules = []
batches = [designations[i:i+100] for i in range(0, len(designations), 100)]

for batch_index, batch in enumerate(tqdm(batches, desc="Traitement des batchs")):
    batch_results = traiter_batch(batch_index, batch, resultats_cumules)
    resultats_cumules.extend(batch_results)
    time.sleep(1)

print("\n Tous les batchs traités. Résultat final : correction.csv")

import pandas as pd

def compter_categories(fichier_csv):
    # Chargement du fichier
    df = pd.read_csv(fichier_csv, encoding='latin1')


    # Comptage des distincts
    nb_sous_familles = df['sous famille'].nunique()
    nb_agregats = df['agregat'].nunique()

    print(f"Nombre total de sous-familles distinctes : {nb_sous_familles}")
    print(f"Nombre total d'agrégats distincts : {nb_agregats}")


# Exemple d'appel
compter_categories("produits_groupes_corriges.csv")

import pandas as pd

# Charger les deux fichiers CSV
df_produits = pd.read_csv("produits_groupes.csv", encoding="utf-8-sig")
df_corrections = pd.read_csv("correction_normalisee_complet.csv", encoding="latin1")

# Effectuer une jointure gauche (on garde tous les produits même si pas de correction)
df_merged = pd.merge(
    df_produits,
    df_corrections[["clé", "sous_famille_corrigee_normalisee", "agregat_corrige_normalise"]],
    on="clé",
    how="left"
)

# Remplacer les colonnes sous famille et agregat si une correction existe
df_merged["sous famille"] = df_merged["sous_famille_corrigee_normalisee"].combine_first(df_merged["sous famille"])
df_merged["agregat"] = df_merged["agregat_corrige_normalise"].combine_first(df_merged["agregat"])

# Supprimer les colonnes de correction temporairement ajoutées
df_merged = df_merged.drop(columns=["sous_famille_corrigee_normalisee", "agregat_corrige_normalise"])

df_merged.to_csv("produits_groupes_corriges.csv", index=False, encoding="utf-8-sig")

print("Remplacement terminé. Fichier sauvegardé sous 'produits_groupes_corriges.csv'.")

import pandas as pd

# Charger les deux fichiers
df_produits = pd.read_csv("groupes_sous_famille_agregat.csv", encoding="utf-8-sig")
df_corrections = pd.read_csv("correction_normalisee_x.csv", encoding="latin1")

# Vérifier que la colonne "clé" existe bien dans les deux fichiers
if "clé" not in df_produits.columns or "clé" not in df_corrections.columns:
    raise KeyError("La colonne 'clé' doit être présente dans les deux fichiers.")

# Identifier les clés présentes dans df_produits mais absentes de df_corrections
cles_manquantes = df_produits[~df_produits["clé"].isin(df_corrections["clé"])]

# Extraire les colonnes utiles : clé, sous famille, agregat
cles_a_ajouter = cles_manquantes[["clé", "sous famille", "agregat"]].copy()

# Renommer les colonnes pour correspondre au format du fichier de corrections
cles_a_ajouter.rename(columns={
    "sous famille": "sous_famille_corrigee_normalisee",
    "agregat": "agregat_corrige_normalise"
}, inplace=True)

# Ajouter les lignes manquantes au fichier de corrections
df_corrections_complet = pd.concat([df_corrections, cles_a_ajouter], ignore_index=True)

# Sauvegarder le fichier complété (vous pouvez remplacer l'ancien si vous voulez)
df_corrections_complet.to_csv("correction_normalisee_complet.csv", index=False, encoding="utf-8-sig")

print("Ajout terminé. Les nouvelles lignes ont été ajoutées à 'correction_normalisee_complet.csv'.")